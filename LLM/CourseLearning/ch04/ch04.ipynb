{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 对未标记数据进行预训练"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b89098e5a2b5d050"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.0\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.7.0\n",
      "torch version: 2.3.1\n",
      "tensorflow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\"]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:28:11.078447900Z",
     "start_time": "2024-06-26T11:28:11.040524500Z"
    }
   },
   "id": "641a0f040be9452a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 在本章中，我们实现了基本模型评估的训练循环和代码，以预训练LLM\n",
    "- 在本章的最后，我们还将OpenAI中公开可用的预训练权重加载到我们的模型中\n",
    "\n",
    "![Alt text](../../../img/LLM/ch04/pretrain.png)\n",
    "\n",
    "- 本章涵盖的主题如下所示\n",
    "\n",
    "![Alt text](../../../img/LLM/ch04/ch04_topic.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d9c5ca27462b2b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1、评估生成文本模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa4e0610fb0213cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 我们在本节开始时简要回顾一下使用上一章中的代码初始化GPT模型\n",
    "- 然后，我们讨论LLM的基本评估指标\n",
    "- 最后，在本节中，我们将这些评估指标应用于训练和验证数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b075635eb2a32ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1、使用GPT生成文本"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd4d0bbb974a1601"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 我们使用上一章中的代码初始化GPT模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb528414076e69b8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "GPTModel(\n  (token_emb): Embedding(50257, 768)\n  (pos_emb): Embedding(256, 768)\n  (drop_emb): Dropout(p=0.1, inplace=False)\n  (transformer_blocks): Sequential(\n    (0): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (1): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (2): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (3): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (4): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (5): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (6): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (7): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (8): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (9): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (10): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (11): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (final_norm): LayerNorm()\n  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from ch04 import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"embedding_dim\": 768,  # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:29:23.607654900Z",
     "start_time": "2024-06-26T11:29:21.283160500Z"
    }
   },
   "id": "bdbe33be1929f3f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 我们使用0.1以上的dropout, 但现在训练LLM而不dropout是相对常见的\n",
    "- 现代LLM在nn中也不使用偏置向量. query、key和value矩阵的线性层（与早期的GPT模型不同）,这是通过设置qkv_bias：False来实现的\n",
    "- 我们只减少了256个token的上下文长度（context_length），以减少训练模型的计算资源需求，而原始的1.24亿参数GPT-2模型使用了1024个token\n",
    "    - 这是为了让更多的读者能够在他们的笔记本电脑上遵循和执行代码示例\n",
    "    - 但是，请随时将context_length增加到1024个token（这不需要任何代码更改）\n",
    "    - 稍后，我们还将从预训练的权重中加载一个上下文长度为1024的模型\n",
    "- 接下来，我们使用上一章中的generate_text_simple函数来生成文本\n",
    "- 此外，我们定义了两个函数，text_to_token_ids和token_ids_to_text，用于在本章中使用的token和文本表示之间进行转换\n",
    "\n",
    "![Alt text](../../../img/LLM/ch04/GPT_process.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "952550c810b51cb4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from ch04 import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:31:52.088187800Z",
     "start_time": "2024-06-26T11:31:49.238357900Z"
    }
   },
   "id": "47f424deae235090"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 正如我们在上面看到的，该模型不能生成好的文本，因为它还没有经过训练\n",
    "- 我们如何测量或捕捉数字形式的“好文本”，以在训练中跟踪它？\n",
    "- 下一小节介绍了用于计算生成输出的损失度量的度量，我们可以使用该度量来衡量训练进度\n",
    "- 关于微调LLM的下一章还将介绍测量模型质量的其他方法"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9911553a36e173ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2、计算文本生成损失：交叉熵与幻觉"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1521d7a1e04f299"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 假设我们有一个输入张量，其中包含2个训练示例（行）的token ID\n",
    "- 与输入相对应，目标包含我们希望模型生成的所需token ID\n",
    "- 请注意，目标是偏移1个位置的输入，如实现数据加载器时所述"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "613d2f1f6e94dc62"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:32:11.818437200Z",
     "start_time": "2024-06-26T11:32:11.746601Z"
    }
   },
   "id": "b597f6d4ed691bac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 将输入提供给模型，我们获得2个输入示例的logits向量，每个示例由3个标记组成\n",
    "- 每个标记是对应于词汇表大小的50257维向量\n",
    "- 应用softmax函数，我们可以将logits张量转化为包含概率得分的同维张量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4a4cc4e17da4081"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "    \n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:32:26.992981Z",
     "start_time": "2024-06-26T11:32:26.876296600Z"
    }
   },
   "id": "bf25c5984eec03a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 下图使用了一个非常小的词汇进行说明，概述了我们如何将概率分数转换回文本，我们在上一章结束时对此进行了讨论\n",
    "\n",
    "![Alt text](../../../img/LLM/ch04/loss_example.png)\n",
    "\n",
    "- 如前一章所述，我们可以应用argmax函数将概率得分转换为预测的token ID\n",
    "- 上面的softmax函数为每个token产生了50257维向量；argmax函数返回该向量中最高概率得分的位置，该位置是给定token的预测token ID\n",
    "- 由于我们有两个输入批次，每个批次有3个token，因此我们获得了2乘3的预测token ID："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d293532fde46933"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:33:04.996934900Z",
     "start_time": "2024-06-26T11:33:04.940087900Z"
    }
   },
   "id": "1c1e221ef773ea3d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 如果我们解码这些token，我们会发现这些token与我们希望模型预测的token（即目标token）截然不同："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff015ac244a303cd"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:33:45.204400500Z",
     "start_time": "2024-06-26T11:33:45.143535Z"
    }
   },
   "id": "39004e8aca0db565"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 那是因为模型还没有经过训练\n",
    "- 为了训练模型，我们需要知道它离正确的预测（目标）有多远\n",
    "\n",
    "![Alt text](../../../img/LLM/ch04/decode_tokenid.png)\n",
    "\n",
    "- 与目标索引相对应的token概率如下："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9867ca20adae63eb"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1:tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2:tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(f\"Text 1:{target_probas_1}\")\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(f\"Text 2:{target_probas_2}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:35:20.602744700Z",
     "start_time": "2024-06-26T11:35:20.566841900Z"
    }
   },
   "id": "7b2ba435ed6d29c8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 我们希望最大化所有这些值，使其接近1的概率\n",
    "- 在数学优化中，使概率得分的对数最大化比使概率得分本身最大化更容易"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "327f87eb6737ceb3"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:35:22.206540700Z",
     "start_time": "2024-06-26T11:35:22.182604600Z"
    }
   },
   "id": "27b80274a49a3387"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 接下来，我们计算平均对数概率"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2846689b75255223"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:35:23.525783600Z",
     "start_time": "2024-06-26T11:35:23.502818100Z"
    }
   },
   "id": "85c9e067d4622a89"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 目标是通过优化模型权重，使该平均对数概率尽可能大\n",
    "- 由于日志的原因，最大可能的值是0，而我们目前距离0很远\n",
    "- 在深度学习中，最小化负平均对数概率值是一种标准惯例，而不是最大化平均对数概率；在我们的例子中，在深度学习中，我们将最小化10.7722，使其接近0，而不是最大化-10.7722\n",
    "- -10.7722的负值，即10.7722，在深度学习中也称为交叉熵损失"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df88a4389eccaf38"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:35:25.428337500Z",
     "start_time": "2024-06-26T11:35:25.375478800Z"
    }
   },
   "id": "a7fa0adfc952141d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- PyTorch已经实现了一个执行前面步骤的cross_entropy函数\n",
    "\n",
    "![Alt text](../../../img/LLM/ch04/cross_entropy.png)\n",
    "\n",
    "- 在我们应用交叉熵函数之前，让我们检查logits和目标的形状"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c73707f94d7d3cef"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:36:36.289556300Z",
     "start_time": "2024-06-26T11:36:36.211761600Z"
    }
   },
   "id": "183b86a64f7469f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 对于PyTorch中的cross-entropy_loss函数，我们希望通过在批次维度上组合这些张量来压平这些张量："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18dda0f50f28f650"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatten logits:torch.Size([6, 50257])\n",
      "Flatten targets:torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(f\"Flatten logits:{logits_flat.shape}\")\n",
    "print(f\"Flatten targets:{targets_flat.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:36:44.000086400Z",
     "start_time": "2024-06-26T11:36:43.978117400Z"
    }
   },
   "id": "463b9e5233e15571"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 注意，目标是token ID，它也表示我们想要最大化的logits张量中的索引位置\n",
    "- PyTorch中的cross_entry函数将自动负责在内部将softmax和log概率计算应用于要最大化的logits中的那些token 索引"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23f68caecd2bf3a5"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "loss = F.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:36:56.937709900Z",
     "start_time": "2024-06-26T11:36:56.842265400Z"
    }
   },
   "id": "368e65884d4cfd31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 一个与交叉熵损失有关的概念是LLM的困惑度\n",
    "- 困惑度只是交叉熵损失的指数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66c0021b28ccf234"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:37:04.580565200Z",
     "start_time": "2024-06-26T11:37:04.525682300Z"
    }
   },
   "id": "8a1a71916eb4f317"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 这种困惑度通常被认为更容易解释，因为它可以被理解为模型在每一步都不确定的有效词汇大小（在上面的例子中，是47678个单词或标记）\n",
    "- 换句话说，困惑度提供了一种衡量模型预测的概率分布与数据集中单词的实际分布匹配程度的指标\n",
    "- 与损失类似，较低的困惑度表明模型预测更接近实际分布"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2c3fb10aad0c3d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3、计算训练和验证集loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89920c49ce6437b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 我们使用相对较小的数据集来训练LLM（事实上，只有一个小故事）\n",
    "- 原因是：\n",
    "    - 你可以在几分钟内在没有合适GPU的笔记本电脑上运行代码示例\n",
    "    - 培训完成得相对较快（几分钟而不是几周），这有利于教育目的\n",
    "    - 我们使用来自公共域的文本，该文本可以包含在此GitHub存储库中，而不会侵犯任何使用权限或扩大存储库大小\n",
    "- 例如，Llama 2 7B在A100 GPU上需要184320 GPU小时才能在2万亿token上进行训练\n",
    "\n",
    "- 在撰写本文时，AWS的8xA100云服务器的小时成本约为30美元\n",
    "- 因此，通过非常规计算，培训该LLM将花费184320/8*$30=690000美元\n",
    "- 下面，我们使用与第2章中使用的数据集相同的数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74b6dfae4c69ee80"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:44:14.148345500Z",
     "start_time": "2024-06-26T11:44:14.102439100Z"
    }
   },
   "id": "3a1db8a5855cc122"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 通过打印前100个单词和后100个单词快速检查加载的文本是否正常"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e11dc59629eb5754"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "print(text_data[:99])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:37:39.672513400Z",
     "start_time": "2024-06-26T11:37:39.647580600Z"
    }
   },
   "id": "ad535893f5b237ea"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "print(text_data[-99:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:37:40.782755200Z",
     "start_time": "2024-06-26T11:37:40.744857700Z"
    }
   },
   "id": "8ecde412b3c60de4"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters:20479\n",
      "Tokens:5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(f\"Characters:{total_characters}\")\n",
    "print(f\"Tokens:{total_tokens}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:44:16.935014700Z",
     "start_time": "2024-06-26T11:44:16.907089800Z"
    }
   },
   "id": "4a83625f6a77d953"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 对于5145个token，文本对于训练LLM来说非常短，但同样，它是出于教育目的（我们稍后也将加载预训练的权重）\n",
    "- 接下来，我们将数据集划分为训练集和验证集，并使用第2章中的数据加载器为LLM训练准备批次\n",
    "- 出于可视化目的，下图假设max_length=6，但对于训练加载程序，我们将max_lengh设置为LLM支持的上下文长度\n",
    "- 为了简单起见，下图仅显示了输入token\n",
    "- 由于我们训练LLM来预测文本中的下一个单词，因此目标看起来与这些输入相同，只是目标移动了一个位置\n",
    "\n",
    "![Alt text](../../../img/LLM/ch04/text_train_and_predict.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd3662dcb112e53a"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from ch04 import create_dataloader_v1\n",
    "\n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:44:21.662838Z",
     "start_time": "2024-06-26T11:44:21.602968100Z"
    }
   },
   "id": "5dd8b9656f55249b"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M['context_length']:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:44:22.618226Z",
     "start_time": "2024-06-26T11:44:22.593260800Z"
    }
   },
   "id": "2dc0ec63aa66d329"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 我们使用相对较小的批量来减少计算资源需求，而且因为数据集一开始就很小\n",
    "- 例如，用1024的批量大小训练Llama 2 7B"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7acd887020d42215"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "print(\"\\nValidation loader\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:44:24.194333900Z",
     "start_time": "2024-06-26T11:44:24.165413600Z"
    }
   },
   "id": "9d5ceb1561afe0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 另一项可选检查，以确保token大小在预期的大致范围内："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5d8f2fdf74da56a"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens:4608\n",
      "Validation tokens:512\n",
      "All tokens:5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "    \n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "    \n",
    "print(f\"Training tokens:{train_tokens}\")\n",
    "print(f\"Validation tokens:{val_tokens}\")\n",
    "print(f\"All tokens:{train_tokens + val_tokens}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:44:27.132127800Z",
     "start_time": "2024-06-26T11:44:27.107195200Z"
    }
   },
   "id": "80abebc9e6c87157"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 接下来，我们实现一个函数来计算给定批次的交叉熵损失\n",
    "- 此外，我们实现了第二个实用程序函数来计算数据加载程序中用户指定数量的批次的损失"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f57ef5e6b83ac63"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = F.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:45:12.917654500Z",
     "start_time": "2024-06-26T11:45:12.862801400Z"
    }
   },
   "id": "e16645dbde757f2b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 如果您的机器具有支持CUDA的GPU，LLM将在GPU上进行训练，而不会对代码进行任何更改\n",
    "- 通过设备设置，我们确保数据加载到与LLM模型相同的设备上"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "602a4178c64c6686"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "    \n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:45:45.398970900Z",
     "start_time": "2024-06-26T11:45:31.826063100Z"
    }
   },
   "id": "546c447846e17594"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Alt text](../../../img/LLM/ch04/3steps_of_LLM_training.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5e9122a3755189"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 LLM训练"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3220c12009884fed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 在本节中，我们最终实现了用于训练LLM的代码\n",
    "- 我们专注于一个简单的训练函数（如果您有兴趣用更先进的技术来增强这个训练函数，如学习率预热、余弦退火和梯度裁剪，请参阅附录D）\n",
    "\n",
    "![Alt text](../../../img/LLM/ch04/train_process.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe7d959cd63a858c"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            \n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch:{epoch+1} (Step {global_step:06d}):\"\n",
    "                      f\"Train Loss {train_loss:.3f}, Val Loss {val_loss:.3f}\")\n",
    "                \n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:47:16.635401800Z",
     "start_time": "2024-06-26T11:47:16.552594900Z"
    }
   },
   "id": "6a652c53e1baecca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 现在，让我们使用上面定义的训练函数来训练LLM："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da3d2925d5cf0ad4"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:47:19.520062700Z",
     "start_time": "2024-06-26T11:47:19.484130600Z"
    }
   },
   "id": "6448064e16568a4f"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 (Step 000000):Train Loss 9.783, Val Loss 9.927\n",
      "Epoch:1 (Step 000005):Train Loss 7.985, Val Loss 8.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▏                                                                | 1/10 [01:26<12:54, 86.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Epoch:2 (Step 000010):Train Loss 6.753, Val Loss 7.048\n",
      "Epoch:2 (Step 000015):Train Loss 6.114, Val Loss 6.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▍                                                         | 2/10 [02:27<09:32, 71.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
      "Epoch:3 (Step 000020):Train Loss 5.525, Val Loss 6.490\n",
      "Epoch:3 (Step 000025):Train Loss 5.324, Val Loss 6.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████▌                                                  | 3/10 [03:28<07:46, 66.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
      "Epoch:4 (Step 000030):Train Loss 4.761, Val Loss 6.360\n",
      "Epoch:4 (Step 000035):Train Loss 4.461, Val Loss 6.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████▊                                           | 4/10 [04:30<06:29, 64.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
      "Epoch:5 (Step 000040):Train Loss 3.833, Val Loss 6.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████                                    | 5/10 [05:22<05:01, 60.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
      "Epoch:6 (Step 000045):Train Loss 3.352, Val Loss 6.139\n",
      "Epoch:6 (Step 000050):Train Loss 2.861, Val Loss 6.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████▏                            | 6/10 [06:21<03:59, 59.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
      "Epoch:7 (Step 000055):Train Loss 2.347, Val Loss 6.138\n",
      "Epoch:7 (Step 000060):Train Loss 2.084, Val Loss 6.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████▍                     | 7/10 [07:26<03:04, 61.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
      "Epoch:8 (Step 000065):Train Loss 1.521, Val Loss 6.176\n",
      "Epoch:8 (Step 000070):Train Loss 1.272, Val Loss 6.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████▌              | 8/10 [08:29<02:04, 62.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
      "Epoch:9 (Step 000075):Train Loss 1.000, Val Loss 6.277\n",
      "Epoch:9 (Step 000080):Train Loss 0.718, Val Loss 6.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████▊       | 9/10 [09:27<01:00, 60.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Epoch:10 (Step 000085):Train Loss 0.506, Val Loss 6.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 10/10 [10:25<00:00, 62.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T11:57:54.879465900Z",
     "start_time": "2024-06-26T11:47:21.652214300Z"
    }
   },
   "id": "c3ae2a46444b33b6"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x300 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    \n",
    "    ax1.plot(epochs_seen, train_losses, label='Training Loss')\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle='-.', label='Validation Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "    \n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel('Tokens seen')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:00:16.332521Z",
     "start_time": "2024-06-26T12:00:15.238299Z"
    }
   },
   "id": "ae198b7042df242b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 看看上面的结果，我们可以看到，该模型一开始会生成不可理解的字符串，而到最后，它能够生成语法上或多或少正确的句子\n",
    "- 然而，基于训练和验证集的损失，我们可以看到模型开始过拟合\n",
    "- 如果我们检查它最后写的几段话，我们会发现它们逐字逐句地包含在训练集中——它只是记住了训练数据\n",
    "- 稍后，我们将介绍可以在一定程度上减轻这种记忆的解码策略\n",
    "- 注意，这里出现过拟合是因为我们有一个非常非常小的训练集，并且我们对它迭代了很多次\n",
    "    - 这里的LLM培训主要用于教育目的；我们主要希望看到模型能够学习生成连贯的文本\n",
    "    - 我们没有花费数周或数月的时间在大量昂贵的硬件上训练这个模型，而是稍后加载预训练的权重\n",
    "\n",
    "![Alt text](../../../img/LLM/ch04/train_function_of_LLM.png)\n",
    "\n",
    "- 如果您有兴趣使用更先进的技术来增强此训练函数，如学习率预热、余弦退火和梯度裁剪，请参阅附录D\n",
    "\n",
    "- 如果您对更大的训练数据集和更长的训练跑感兴趣，请参阅/03_bonus_preataining_on_gutenberg"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8443d8ca5e456f72"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 控制随机性的解码策略"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55cfb4a930bf9761"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 推理相对便宜，LLM相对较小，作为我们上面训练的GPT模型，因此没有必要使用GPU来进行推理，以防您使用GPU来训练它\n",
    "- 使用我们前面在简单训练函数中使用的generate_text_simple函数（来自上一章），我们可以一次生成一个单词（或标记）的新文本\n",
    "- 下一个生成的token对应于词汇表中所有token中最大概率得分的token"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "310b7e32eb3f5f13"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n"
     ]
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:00:26.120680300Z",
     "start_time": "2024-06-26T12:00:23.291508300Z"
    }
   },
   "id": "82efcc617d48a972"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 即使我们多次执行上面的generate_text_simple函数，LLM也将始终生成相同的输出\n",
    "- 现在，我们引入两个概念，即所谓的decode策略，来修改generate_text_simple：temperature缩放和top-k采样\n",
    "- 这些将允许模型控制生成文本的随机性和多样性"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0e599648246397a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 temperature缩放"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "913ab08cf2d16cde"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 以前，我们总是使用torch.argmax对具有最高概率的token进行采样，作为下一个token\n",
    "- 为了增加多样性，我们可以使用torch.multinomial(probs，num_samples=1)对下一个token进行采样，从概率分布中采样\n",
    "- 这里，每个索引被选中的几率对应于其在输入张量中的概率\n",
    "- 以下是生成下一个token的简要回顾，假设用于说明的词汇非常少："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e0cd0e062761895"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Suppose input is \"every effort moves you\", and the LLM\n",
    "# returns the following logits for the next token:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "print(inverse_vocab[next_token_id])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:00:32.882556600Z",
     "start_time": "2024-06-26T12:00:32.856945100Z"
    }
   },
   "id": "92409f5aad9605bf"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "\n",
    "print(inverse_vocab[next_token_id])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:00:34.627813400Z",
     "start_time": "2024-06-26T12:00:34.536028300Z"
    }
   },
   "id": "5abd24696d258d20"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:00:38.782292400Z",
     "start_time": "2024-06-26T12:00:38.690975800Z"
    }
   },
   "id": "8f6a5b492a62110a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 我们不是通过torch.argmax来确定最可能的token，而是使用torch.multinomial(probas，num_samples=1)通过从softmax分布中采样来确定最有可能的token\n",
    "- 为了便于说明，让我们看看当我们使用原始softmax概率对下一个token采样1000次时会发生什么：\n",
    "- 我们可以通过一个称为 temperature缩放 的概念来控制分布和选择过程\n",
    "- temperature缩放 只是一个花哨的词，用来将logits除以大于0的数字\n",
    "- 在应用softmax后，温度大于1将导致更均匀分布的token概率\n",
    "- 应用softmax后，小于1的温度将导致更可靠（更尖锐或更峰值）的分布"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f986cfcbee39acdb"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "temperatures = [1, 0.1, 5]\n",
    "\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:00:56.570700400Z",
     "start_time": "2024-06-26T12:00:56.509831300Z"
    }
   },
   "id": "b61bd1678f5bbf4e"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x300 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:00:59.214923900Z",
     "start_time": "2024-06-26T12:00:57.193640300Z"
    }
   },
   "id": "dcbbc9ee9671aee9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 我们可以看到，通过温度0.1的重新缩放导致更尖锐的分布，接近torch.argmax，因此几乎总是选择最有可能的单词"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5061af12a1f5512"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "992 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "8 x toward\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:01:03.149865400Z",
     "start_time": "2024-06-26T12:01:03.076062700Z"
    }
   },
   "id": "7dcb8e49ac5e897"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 x closer\n",
      "68 x every\n",
      "55 x effort\n",
      "223 x forward\n",
      "102 x inches\n",
      "50 x moves\n",
      "43 x pizza\n",
      "218 x toward\n",
      "88 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:01:04.034682800Z",
     "start_time": "2024-06-26T12:01:03.945920200Z"
    }
   },
   "id": "fe76b8fbe943f551"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 假设LLM输入“every effort moves you”，使用上述方法有时会导致无意义的文本，例如“every effort moves you pizza”，4.3%的时间（1000次中有43次）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70eba446b2d76f03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Top-k 采样"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf61b693643fb05d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 为了能够使用更高的temperature来增加输出多样性并降低无意义句子的概率，我们可以将采样的标记限制为前k个最可能的标记：\n",
    "\n",
    "![Alt text](../../../img/LLM/ch04/topk_sampling.png)\n",
    "\n",
    "- (请注意，此图中的数字被截断为小数点后的两位数，以减少视觉混乱。Softmax行中的值加起来应为1.0)\n",
    "- 在代码中，我们可以实现如下："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cdfe8e8994d7327"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits:tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions:tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(f\"Top logits:{top_logits}\")\n",
    "print(f\"Top positions:{top_pos}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:01:12.392303800Z",
     "start_time": "2024-06-26T12:01:12.354380500Z"
    }
   },
   "id": "b3772b1c153e73b7"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')), \n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:01:15.928272500Z",
     "start_time": "2024-06-26T12:01:15.906332Z"
    }
   },
   "id": "15580e5eb5083dab"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:01:22.979976300Z",
     "start_time": "2024-06-26T12:01:22.715067500Z"
    }
   },
   "id": "fd60d682bea68ff3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 修改文本生成功能"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41a1cff113a76db5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 前两小节介绍了温度采样和top-k采样\n",
    "- 让我们使用这两个概念来修改我们之前用于通过LLM生成文本的generate_simple函数，创建一个新的generate函数："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf3408cd6ccabcc2"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "            \n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            \n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            \n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "            \n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    \n",
    "    return idx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:01:36.168170200Z",
     "start_time": "2024-06-26T12:01:36.128277500Z"
    }
   },
   "id": "ba9420eadb87a1c9"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to my surprise, a little it was the\n",
      "\"Ah enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:01:37.945129600Z",
     "start_time": "2024-06-26T12:01:36.578075Z"
    }
   },
   "id": "9ea07d49a1e04d48"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 PyTorch中加载和保存模型重量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3653af8bc9264033"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 训练LLM的计算成本很高，因此能够保存和加载LLM权重至关重要\n",
    "\n",
    "![Alt text](../../../img/LLM/ch04/weight_saving.png)\n",
    "\n",
    "- PyTorch中建议的方法是通过将torch.save函数应用于.state_dict()方法来保存"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9aad0a453970505"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T08:50:20.201914700Z",
     "start_time": "2024-06-20T08:50:15.275008Z"
    }
   },
   "id": "3bc4b9b494cfc0f6"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "GPTModel(\n  (token_emb): Embedding(50257, 768)\n  (pos_emb): Embedding(256, 768)\n  (drop_emb): Dropout(p=0.1, inplace=False)\n  (transformer_blocks): Sequential(\n    (0): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (1): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (2): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (3): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (4): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (5): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (6): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (7): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (8): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (9): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (10): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (11): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=False)\n        (W_k): Linear(in_features=768, out_features=768, bias=False)\n        (W_v): Linear(in_features=768, out_features=768, bias=False)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (final_norm): LayerNorm()\n  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n)"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T08:50:50.171131500Z",
     "start_time": "2024-06-20T08:50:43.964842300Z"
    }
   },
   "id": "37c8c22b94f82a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 使用Adam或AdamW等自适应优化器而不是常规SGD来训练LLM是很常见的\n",
    "- 这些自适应优化器为每个模型权重存储额外的参数，因此，如果我们计划稍后继续预训练，也可以保存这些参数："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb8f3c3ff5600b3d"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T08:51:09.721916300Z",
     "start_time": "2024-06-20T08:50:53.851586700Z"
    }
   },
   "id": "2728313db94a4c96"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T08:51:29.228969100Z",
     "start_time": "2024-06-20T08:51:09.742860400Z"
    }
   },
   "id": "c204647d2a19861e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5 从OpenAI加载预训练权重"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cd314c61a4279c7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 以前，我们只使用一本非常小的短篇小说来训练一个小的GPT-2模型，用于教育目的\n",
    "- 感兴趣的读者还可以在中找到完整的古腾堡项目图书语料库的更长时间的预训练/03_bonus_preataining_on_gutenberg\n",
    "- 幸运的是，我们不必花费数万至数十万美元在大型预训练语料库上对模型进行预训练，而是可以加载OpenAI提供的预训练权重\n",
    "- 有关从Hugging Face加载权重的替代方法\n",
    "- 首先，一些样板代码从OpenAI下载文件并将权重加载到Python中\n",
    "- 由于OpenAI使用了TensorFlow，我们将不得不安装并使用TensorFlow来加载权重；tqdm是进度条库\n",
    "- 取消注释并运行下一个单元以安装所需的库"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffcb845fe7a59b0f"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n",
      "tqdm version: 4.66.4\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:01:47.595358400Z",
     "start_time": "2024-06-26T12:01:47.547457600Z"
    }
   },
   "id": "2b7e45817026bcf5"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from gpt_download import download_and_load_gpt2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:02:00.874613100Z",
     "start_time": "2024-06-26T12:01:48.598648300Z"
    }
   },
   "id": "568ff0882c854be3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 然后，我们可以下载1.24亿参数模型的模型权重，如下所示："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fe122a8e1dac43f"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:02:13.250534600Z",
     "start_time": "2024-06-26T12:02:00.877588300Z"
    }
   },
   "id": "253cc7674d347336"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:02:21.885332500Z",
     "start_time": "2024-06-26T12:02:21.850299Z"
    }
   },
   "id": "401c42e2dcc8fc4d"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys:dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parameter dictionary keys:{params.keys()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:02:37.701823500Z",
     "start_time": "2024-06-26T12:02:37.661930900Z"
    }
   },
   "id": "b71927d60411debe"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions:(50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params['wte'])\n",
    "print(f\"Token embedding weight tensor dimensions:{params['wte'].shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T12:04:35.346810100Z",
     "start_time": "2024-06-26T12:04:35.284975300Z"
    }
   },
   "id": "2a3801c5407734f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 除此之外，“355M”、“774M”和“1558M”也支持model_size参数\n",
    "- 下图总结了这些不同尺寸模型之间的差异：\n",
    "\n",
    "![Alt text](../../../img/LLM/ch04/model_size.png)\n",
    "\n",
    "- 综上，我们将124M GPT-2模型权重加载到Python中，但是我们仍然需要将它们转移到我们的GPTModel实例中\n",
    "- 首先，我们初始化一个新的GPTModel实例\n",
    "- 请注意，原始GPT模型使用偏差向量初始化了多头注意力模块中查询、键和值矩阵的线性层，这不是必需的或推荐的；然而，为了能够正确地加载权重，我们也必须通过在实现中将qkv_bias设置为True来启用这些权重\n",
    "- 我们还使用了原始GPT-2模型使用的1024令牌上下文长度"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef1ce795bafd73da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-06-26T12:07:13.819687200Z"
    }
   },
   "id": "cb74ceed6b822553"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 下一个任务是将OpenAI权重分配给GPTModel实例中相应的权重张量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c512ae9dac4f0c31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return nn.Parameter(torch.tensor(right))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f79b81840cff2ddd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.token_emb.weight = assign(gpt.token_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.transformer_blocks[b].attention.W_q.weight = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_q.weight, q_w.T)\n",
    "        gpt.transformer_blocks[b].attention.W_k.weight = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_k.weight, k_w.T)\n",
    "        gpt.transformer_blocks[b].attention.W_v.weight = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_v.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.transformer_blocks[b].attention.W_q.bias = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_q.bias, q_b)\n",
    "        gpt.transformer_blocks[b].attention.W_k.bias = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_k.bias, k_b)\n",
    "        gpt.transformer_blocks[b].attention.W_v.bias = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_v.bias, v_b)\n",
    "\n",
    "        gpt.transformer_blocks[b].attention.out_proj.weight = assign(\n",
    "            gpt.transformer_blocks[b].attention.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.transformer_blocks[b].attention.out_proj.bias = assign(\n",
    "            gpt.transformer_blocks[b].attention.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.transformer_blocks[b].ffn.layers[0].weight = assign(\n",
    "            gpt.transformer_blocks[b].ffn.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.transformer_blocks[b].ffn.layers[0].bias = assign(\n",
    "            gpt.transformer_blocks[b].ffn.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.transformer_blocks[b].ffn.layers[2].weight = assign(\n",
    "            gpt.transformer_blocks[b].ffn.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.transformer_blocks[b].ffn.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ffn.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.transformer_blocks[b].norm1.scale = assign(\n",
    "            gpt.transformer_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.transformer_blocks[b].norm1.shift = assign(\n",
    "            gpt.transformer_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.transformer_blocks[b].norm2.scale = assign(\n",
    "            gpt.transformer_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.transformer_blocks[b].norm2.shift = assign(\n",
    "            gpt.transformer_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45f9075245fa9a4f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 如果模型加载正确，我们可以使用之前的生成函数来生成新文本："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7262be81918a4410"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddb79cc593b44077"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 我们知道我们正确地加载了模型权重，因为模型可以生成连贯的文本；即使我们犯了一个小错误，该模式也无法做到这一点\n",
    "- 有关从Hugging Face加载权重的替代方法"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6059f05d762dcd6d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "llm",
   "language": "python",
   "display_name": "LLM"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
