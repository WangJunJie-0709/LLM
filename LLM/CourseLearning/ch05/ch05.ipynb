{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 文本分类的微调"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ef8604639765aef"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.0\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.7.0\n",
      "torch version: 2.3.1\n",
      "tensorflow version: 2.16.1\n",
      "pandas version: 2.2.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\",\n",
    "        \"pandas\"\n",
    "        ]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:18:51.852176400Z",
     "start_time": "2024-06-28T03:18:51.806297300Z"
    }
   },
   "id": "da0fc30e3953a3d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Alt text](../../../img/LLM/ch05/classify_finetune.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61709d1baf927cbe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1、不同类别的微调"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9500b15707949a2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 微调语言模型最常见的方法是指令微调和分类微调\n",
    "- 下面描述的指令微调是下一章的主题\n",
    "\n",
    "![Alt text](../../../img/LLM/ch05/instruction_finetuning.png)\n",
    "\n",
    "- 如果你有机器学习的背景，本章的主题是分类微调，这是一个你可能已经熟悉的过程——例如，它类似于训练卷积网络来对手写数字进行分类\n",
    "- 在分类微调中，我们有特定数量的类标签（例如，“垃圾邮件”和“非垃圾邮件”），模型可以输出这些标签\n",
    "- 分类微调模型只能预测它在训练中看到的类（例如，“垃圾邮件”或“非垃圾邮件”），而指令微调模型通常可以执行许多任务\n",
    "- 我们可以把分类微调模型看作是一个非常专业的模型；在实践中，创建一个专门的模型要比创建一个在许多不同任务上表现良好的多面手模型容易得多\n",
    "\n",
    "![Alt text](../../../img/LLM/ch05/classify_finetuning.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0c6d2351374de56"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2、数据集准备"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "866c88d9954e57f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Alt text](../../../img/LLM/ch05/stage1_classify_finetune.png)\n",
    "\n",
    "- 本节准备用于分类微调的数据集\n",
    "- 我们使用由垃圾邮件和非垃圾邮件组成的数据集来微调LLM以对其进行分类\n",
    "- 首先，我们下载并解压缩数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70b68facaec71814"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:18:58.218393700Z",
     "start_time": "2024-06-28T03:18:58.202405100Z"
    }
   },
   "id": "d2a0c616b7c0ba9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 数据集被保存为一个以制表符分隔的文本文件，我们可以将其加载到Panda DataFrame中"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac7b25d2c6c3e9c6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "     Label                                               Text\n0      ham  Go until jurong point, crazy.. Available only ...\n1      ham                      Ok lar... Joking wif u oni...\n2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3      ham  U dun say so early hor... U c already then say...\n4      ham  Nah I don't think he goes to usf, he lives aro...\n...    ...                                                ...\n5567  spam  This is the 2nd time we have tried 2 contact u...\n5568   ham               Will ü b going to esplanade fr home?\n5569   ham  Pity, * was in mood for that. So...any other s...\n5570   ham  The guy did some bitching but I acted like i'd...\n5571   ham                         Rofl. Its true to its name\n\n[5572 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5567</th>\n      <td>spam</td>\n      <td>This is the 2nd time we have tried 2 contact u...</td>\n    </tr>\n    <tr>\n      <th>5568</th>\n      <td>ham</td>\n      <td>Will ü b going to esplanade fr home?</td>\n    </tr>\n    <tr>\n      <th>5569</th>\n      <td>ham</td>\n      <td>Pity, * was in mood for that. So...any other s...</td>\n    </tr>\n    <tr>\n      <th>5570</th>\n      <td>ham</td>\n      <td>The guy did some bitching but I acted like i'd...</td>\n    </tr>\n    <tr>\n      <th>5571</th>\n      <td>ham</td>\n      <td>Rofl. Its true to its name</td>\n    </tr>\n  </tbody>\n</table>\n<p>5572 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:19:01.675872100Z",
     "start_time": "2024-06-28T03:18:59.985587300Z"
    }
   },
   "id": "9da08162c17ea90b"
  },
  {
   "cell_type": "markdown",
   "source": [
    " - 当我们检查类分布时，我们发现数据中包含“ham”（即“非垃圾邮件”）的频率远高于“垃圾邮件”"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1480437bc24ea53d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:19:03.123580800Z",
     "start_time": "2024-06-28T03:19:03.099645100Z"
    }
   },
   "id": "8dd9a080e7d5c67a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 为了简单起见，而且因为出于教育目的，我们更喜欢小的数据集（这将使更快地微调LLM成为可能），我们对数据集进行了子采样（欠采样），使其包含每个类的747个实例\n",
    "- （除了采样不足之外，还有其他几种处理类平衡的方法，但它们不在LLM书籍的范围内；您可以在不平衡学习用户指南中找到示例和更多信息）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7274b301203b1053"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:19:04.706161Z",
     "start_time": "2024-06-28T03:19:04.688181500Z"
    }
   },
   "id": "650959fdd824ddbf"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:19:05.895745300Z",
     "start_time": "2024-06-28T03:19:05.879760100Z"
    }
   },
   "id": "419a7d0ddf6d8bb6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 现在，让我们定义一个函数，将数据集随机划分为训练、验证和测试集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14cab16f6a7ee749"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    \n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "    \n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "    \n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:19:06.909411100Z",
     "start_time": "2024-06-28T03:19:06.854558800Z"
    }
   },
   "id": "625bc145e33bbada"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3、创建数据加载程序"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52e2ab171947e895"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 请注意，文本消息具有不同的长度；如果我们想在一批中组合多个训练示例，我们必须\n",
    "    - 将所有消息截断为数据集中或批处理中最短消息的长度\n",
    "    - 将所有消息填充到数据集中或批处理中最长消息的长度\n",
    "- 我们选择选项2，并将所有消息填充到数据集中最长的消息中\n",
    "- 为此，我们使用<|endoftext|>作为填充标记，如第2章所述\n",
    "\n",
    "![Alt text](../../../img/LLM/ch05/token_padding.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b94754bae9acc952"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:19:11.514939500Z",
     "start_time": "2024-06-28T03:19:10.354243100Z"
    }
   },
   "id": "243d87b4f767b095"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 下面的SpamDataset类标识训练数据集中最长的序列，并将填充标记添加到其他序列以匹配该序列长度"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "598afb2efc9130f0"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "        \n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "            \n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "      \n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encode_length = len(encoded_text)\n",
    "            if encode_length > max_length:\n",
    "                max_length = encode_length\n",
    "        return max_length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:19:19.357917100Z",
     "start_time": "2024-06-28T03:19:13.006645500Z"
    }
   },
   "id": "df52cf0364b2a7f2"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:19:20.665216700Z",
     "start_time": "2024-06-28T03:19:20.630310800Z"
    }
   },
   "id": "335ce59f83b25940"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 我们还将验证和测试集添加到最长的训练序列中\n",
    "- 请注意，比最长训练示例更长的验证和测试集样本将通过SpamDataset代码中的encode_text[：self.max_length]截断\n",
    "- 这种行为是完全可选的，如果我们在验证和测试集的情况下都将max_length设置为None，它也会很好地工作"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86fc47ba25ef8a0a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:19:22.631973600Z",
     "start_time": "2024-06-28T03:19:22.593081200Z"
    }
   },
   "id": "84bfe3d2148b3138"
  },
  {
   "cell_type": "markdown",
   "source": [
    "接下来，我们使用数据集实例化数据加载程序，这与前几章中创建数据加载程序类似\n",
    "\n",
    "![Alt text](../../../img/LLM/ch05/dataloader.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8dcc0860faba87c4"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:19:24.587889500Z",
     "start_time": "2024-06-28T03:19:24.551986100Z"
    }
   },
   "id": "74ec7118f00aa807"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 作为验证步骤，我们对数据加载程序进行迭代，并确保批次中每个包含8个训练示例，其中每个训练示例由120个token组成"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "338c6e1dd7e9a84b"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions:\", target_batch.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:19:26.140688500Z",
     "start_time": "2024-06-28T03:19:26.020978700Z"
    }
   },
   "id": "b06146e94ba37b10"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 最后，让我们打印每个数据集中的批次总数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23ba5e73d6bbffae"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:19:27.462675600Z",
     "start_time": "2024-06-28T03:19:27.442729500Z"
    }
   },
   "id": "5f4d1d85fce837a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4、使用预先训练的权重初始化模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad67a28196f851b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 在本节中，我们初始化上一章中使用的预训练模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de0f6df15323909b"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"embedding_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"embedding_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"embedding_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"embedding_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:19:32.099033100Z",
     "start_time": "2024-06-28T03:19:32.089031500Z"
    }
   },
   "id": "6d9853b583350a56"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": "GPTModel(\n  (token_emb): Embedding(50257, 768)\n  (pos_emb): Embedding(1024, 768)\n  (drop_emb): Dropout(p=0.0, inplace=False)\n  (transformer_blocks): Sequential(\n    (0): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=True)\n        (W_k): Linear(in_features=768, out_features=768, bias=True)\n        (W_v): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (1): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=True)\n        (W_k): Linear(in_features=768, out_features=768, bias=True)\n        (W_v): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (2): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=True)\n        (W_k): Linear(in_features=768, out_features=768, bias=True)\n        (W_v): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (3): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=True)\n        (W_k): Linear(in_features=768, out_features=768, bias=True)\n        (W_v): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (4): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=True)\n        (W_k): Linear(in_features=768, out_features=768, bias=True)\n        (W_v): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (5): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=True)\n        (W_k): Linear(in_features=768, out_features=768, bias=True)\n        (W_v): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (6): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=True)\n        (W_k): Linear(in_features=768, out_features=768, bias=True)\n        (W_v): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (7): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=True)\n        (W_k): Linear(in_features=768, out_features=768, bias=True)\n        (W_v): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (8): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=True)\n        (W_k): Linear(in_features=768, out_features=768, bias=True)\n        (W_v): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (9): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=True)\n        (W_k): Linear(in_features=768, out_features=768, bias=True)\n        (W_v): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (10): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=True)\n        (W_k): Linear(in_features=768, out_features=768, bias=True)\n        (W_v): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (11): TransformerBlock(\n      (attention): MultiHeadAttention(\n        (W_q): Linear(in_features=768, out_features=768, bias=True)\n        (W_k): Linear(in_features=768, out_features=768, bias=True)\n        (W_v): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ffn): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n  )\n  (final_norm): LayerNorm()\n  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from ch05 import GPTModel, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size, \"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:19:58.107691300Z",
     "start_time": "2024-06-28T03:19:32.951846Z"
    }
   },
   "id": "6b4c35dba6ffa2af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 为了确保模型被正确加载，让我们仔细检查一下它是否生成了连贯的文本"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "293e83aeeafe7798"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work.\n",
      "\n",
      "The second step is to understand the importance of your work.\n",
      "\n",
      "The third step is to understand the importance of your work.\n",
      "\n",
      "The fourth step is\n"
     ]
    }
   ],
   "source": [
    "from ch05 import generate_text_simple, text_to_token_ids, token_ids_to_text\n",
    "\n",
    "text1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text1, tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T03:22:32.726034600Z",
     "start_time": "2024-06-28T03:22:27.034596200Z"
    }
   },
   "id": "9b5768d53cd379f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 在我们将模型作为分类器进行微调之前，让我们看看该模型是否已经可以通过提示对垃圾邮件进行分类"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e73f6d712f31b98"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG['context_length']\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T06:41:38.152056800Z",
     "start_time": "2024-06-28T06:41:30.889987700Z"
    }
   },
   "id": "3f5d948c857ad538"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 正如我们所看到的，该模型在以下说明方面不是很好\n",
    "- 这是意料之中的事，因为它只是经过了预训练，而不是指令微调（指令微调将在下一章中介绍）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fa76ce03ad74a8d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5、添加分类head"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b10ead215121d53d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Alt text](../../../img/LLM/ch05/classify_head.png)\n",
    "\n",
    "- 在本节中，我们将修改预训练的LLM，使其为分类微调做好准备\n",
    "- 让我们先来看看模型体系结构"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52105f069ab48a4d"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (token_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (transformer_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T06:44:23.087300500Z",
     "start_time": "2024-06-28T06:44:22.986544400Z"
    }
   },
   "id": "bb45f975991aa528"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 在上面，我们可以看到我们在第3章中实现的架构\n",
    "- 目标是替换和微调输出层\n",
    "- 为了实现这一点，我们首先冻结模型，这意味着我们使所有层都不可训练"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41508d9d28dc6b09"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T06:45:33.850792800Z",
     "start_time": "2024-06-28T06:45:33.684633200Z"
    }
   },
   "id": "4dae683dda228642"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 然后，我们替换输出层（model.out_head），它最初将层输入映射到50257个维度（词汇表的大小）\n",
    "- 由于我们对二进制分类的模型进行了微调（预测了两个类，“垃圾邮件”和“非垃圾邮件”），我们可以替换输出层，如下所示，默认情况下可以进行训练\n",
    "- 请注意，我们使用BASE_CONFIG[“emb_dim”]（在“gpt2 small（124M）”模型中等于768）来保持下面的代码更通用"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fd754880e999274"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"embedding_dim\"], out_features=num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T06:47:57.541059Z",
     "start_time": "2024-06-28T06:47:57.412405400Z"
    }
   },
   "id": "7b189aa510d3ee66"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 从技术上讲，只训练输出层就足够了\n",
    "- 然而，正如我在微调大型语言模型中发现的那样，实验表明微调附加层可以显著提高性能\n",
    "- 因此，我们还使最后一个Transformer块和将最后一个Transformer块连接到输出层的最后一个LayerNorm模块可训练\n",
    "\n",
    "![Alt text](../../../img/LLM/ch05/finetune_architecture.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87cc4ebfe983ae2"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "for param in model.transformer_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T06:50:39.652891900Z",
     "start_time": "2024-06-28T06:50:39.521214400Z"
    }
   },
   "id": "bd7ed60590afbda3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 我们仍然可以使用与前几章中类似的模型\n",
    "- 例如，让我们给它一些文本输入"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14078e2408602b02"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T06:51:52.707014400Z",
     "start_time": "2024-06-28T06:51:52.580351500Z"
    }
   },
   "id": "1f6ce3dc56d993ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 与前几章不同的是，它现在有两个输出维度，而不是50257"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8be44dc67950d2b8"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T06:54:18.462334200Z",
     "start_time": "2024-06-28T06:54:16.678741Z"
    }
   },
   "id": "5aab011d48c5665b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 如前几章所述，对于每个输入token，都有一个输出向量\n",
    "- 由于我们向模型提供了一个具有4个输入标记的文本样本，因此输出由上面的4个二维输出向量组成\n",
    "\n",
    "![Alt text](../../../img/LLM/ch05/finetune_architecture_example.png)\n",
    "\n",
    "- 在第2章中，我们讨论了注意力机制，它将每个输入token连接到另一个输入token\n",
    "- 在第2章中，我们还介绍了在类GPT模型中使用的因果注意掩码；该因果掩码使当前token只关注当前和以前的token位置\n",
    "- 基于这种因果注意机制，第四个（最后一个）令牌包含了所有token中最多的信息，因为它是唯一包含所有其他token信息的token\n",
    "- 因此，我们对最后一个token特别感兴趣，我们将为垃圾邮件分类任务对其进行微调"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba63a31f169aeba6"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T08:28:01.254651800Z",
     "start_time": "2024-06-28T08:28:01.099534200Z"
    }
   },
   "id": "27d6081a0f5d2e2b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Alt text](../../../img/LLM/ch05/casual_attention_mask.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8993765bc0b3823"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6、计算分类损失和准确率"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acea9b1a870293a2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Alt text](../../../img/LLM/ch05/process_loss_accuracy.png)\n",
    "\n",
    "- 在解释损失计算之前，让我们简要了解一下模型输出是如何转换为类标签的\n",
    "\n",
    "![Alt text](../../../img/LLM/ch05/output_to_class_label.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d3cc0d91acd2861"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T08:33:57.203797700Z",
     "start_time": "2024-06-28T08:33:57.165868800Z"
    }
   },
   "id": "34a2db4da4d8fb40"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 与第4章类似，我们通过softmax函数将输出（logits）转换为概率得分，然后通过argmax函数获得最大概率值的索引位置"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26be53ffd9f1642d"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label\", label.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T08:37:38.997054200Z",
     "start_time": "2024-06-28T08:37:38.890339800Z"
    }
   },
   "id": "d489f49b18f9fbfb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 请注意，如第4章所述，softmax函数在这里是可选的，因为最大的输出对应于最大的概率分数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f40574a11e277f88"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label\", label.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T08:39:44.095418100Z",
     "start_time": "2024-06-28T08:39:44.038459700Z"
    }
   },
   "id": "6dd260b916fdbf7b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 我们可以将这一概念应用于计算所谓的分类精度，即计算给定数据集中正确预测的百分比\n",
    "- 为了计算分类精度，我们可以将前面基于argmax的预测代码应用于数据集中的所有示例，并计算正确预测的分数，如下所示："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "660390b7ba90a4b9"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    \n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T09:02:15.357482900Z",
     "start_time": "2024-06-28T09:02:15.309611200Z"
    }
   },
   "id": "49a85e3f69b25d74"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 让我们应用该函数来计算不同数据集的分类精度"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d29dfd972890a578"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T09:08:25.660922500Z",
     "start_time": "2024-06-28T09:07:52.040235900Z"
    }
   },
   "id": "556a33852cc7e9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 正如我们所看到的，预测精度不是很好，因为我们还没有微调模型\n",
    "- 在我们开始微调（/训练）之前，我们首先必须定义训练期间要优化的损失函数\n",
    "\n",
    "- 目标是最大限度地提高垃圾邮件分类模型的准确性；然而，分类精度不是一个可微函数\n",
    "\n",
    "- 因此，相反，我们将交叉熵损失最小化，作为最大化分类精度的代理（您可以在我免费提供的深度学习导论课程的第8讲中了解更多关于此主题的信息）\n",
    "\n",
    "- 这里的calc_loss_batch函数与第5章中的相同，只是我们只对优化最后一个token模型 (input_batch) [：，-1，：]而不是所有token模型 (input_batch)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54007483e8a4f5a2"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T09:31:20.662370400Z",
     "start_time": "2024-06-28T09:31:20.593554700Z"
    }
   },
   "id": "f5761ec460103597"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T09:32:35.546151Z",
     "start_time": "2024-06-28T09:32:35.474812600Z"
    }
   },
   "id": "e88ab38c5cb246db"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.525\n",
      "Test loss: 2.413\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T09:35:02.755308900Z",
     "start_time": "2024-06-28T09:34:42.204534700Z"
    }
   },
   "id": "a5e098858f24712a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 在下一节中，我们训练模型以优化损失值，从而提高分类精度"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c9b9f4139b2b4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7、使用有监督数据微调模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "726945faeb2e9c51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "64b86d1846d6a784"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "llm",
   "language": "python",
   "display_name": "LLM"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
